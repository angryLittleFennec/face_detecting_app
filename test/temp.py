import logging
import os
import cv2
import numpy as np
import dlib
import requests
from ultralytics import YOLO
from threading import Thread, Lock
from queue import Queue
import argparse
import time
import sys
from collections import deque

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è Kubernetes
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)  # –í—ã–≤–æ–¥–∏–º –≤ stdout –¥–ª—è Kubernetes
    ]
)
logger = logging.getLogger(__name__)

# –û—Ç–∫–ª—é—á–∞–µ–º –ª–æ–≥–∏ OpenCV –∏ YOLO
os.environ["OPENCV_FFMPEG_CAPTURE_OPTIONS"] = "rtsp_transport;tcp|buffer_size;4096|stimeout;2000000|max_delay;200000|flags;low_delay|err_detect;ignore_err|skip_frame;0|skip_loop_filter;48|flags2;showall|fflags;nobuffer|analyzeduration;1000000|probesize;32"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ RTSP
RTSP_INPUT_URL = os.getenv("RTSP_IN", "rtsp://mediamtx-svc:8554/mediamtx/stream3")
RTSP_OUTPUT_URL = os.getenv("RTSP_OUT", "rtsp://mediamtx-svc:8554/mediamtx/newstream1")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ YOLO
FACE_MODEL = YOLO("ml_models/yolov8n-face.pt")
FACE_MODEL.conf = 0.5
FACE_MODEL.iou = 0.45
FACE_MODEL.agnostic = True
FACE_MODEL.max_det = 10
FACE_MODEL.classes = None
FACE_MODEL.verbose = False

# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
TARGET_WIDTH = 640
TARGET_HEIGHT = 360
YOLO_WIDTH = 640  # –†–∞–∑–º–µ—Ä –¥–ª—è YOLO
YOLO_HEIGHT = 360

# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
process_every_n_frames = 5  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π 5-–π –∫–∞–¥—Ä
face_recognition_interval = 5  # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º –ª–∏—Ü–∞ –Ω–∞ –∫–∞–∂–¥–æ–º 5-–º –∫–∞–¥—Ä–µ

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ YOLO
OBJECT_MODEL = YOLO("ml_models/yolov8n.pt")  # –ú–æ–¥–µ–ª—å –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤
HELMET_MODEL = YOLO("ml_models/hemletYoloV8_100epochs.pt")  # –ú–æ–¥–µ–ª—å –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —à–ª–µ–º–æ–≤
face_detector = dlib.get_frontal_face_detector()
shape_predictor = dlib.shape_predictor("ml_models/shape_predictor_68_face_landmarks.dat")
face_rec_model = dlib.face_recognition_model_v1("ml_models/dlib_face_recognition_resnet_model_v1.dat")

used_faces = []  # –°–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —É–∂–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã—Ö –ª–∏—Ü
url = "http://face-recognition-svc:80/find_face"
LOGGING_SERVICE_URL = "http://logging_service:8000/log"  # URL —Å–µ—Ä–≤–∏—Å–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –±—É—Ñ–µ—Ä–∞
frame_queue = Queue(maxsize=3)
detection_queue = Queue(maxsize=3)
detection_lock = Lock()

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
frame_times = []
target_fps = 30
last_face_recognition_time = 0

# –ö—ç—à –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –ª–∏—Ü
face_embedding_cache = {}
CACHE_SIZE = 100  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞

# –ö—ç—à –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–µ—Ç–µ–∫—Ü–∏–π
last_detections = []  # –°–ø–∏—Å–æ–∫ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –ª–∏—Ü
MAX_DETECTIONS_CACHE = 10  # –†–∞–∑–º–µ—Ä –∫—ç—à–∞
detection_lifetime = 10  # –í—Ä–µ–º—è –∂–∏–∑–Ω–∏ –¥–µ—Ç–µ–∫—Ü–∏–∏ –≤ –∫–∞–¥—Ä–∞—Ö

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–∏
current_interpolation = []  # –¢–µ–∫—É—â–∏–µ –∏–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏

# –î–æ–±–∞–≤–ª—è–µ–º –∫–ª–∞—Å—Å –¥–ª—è –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è
class Profiler:
    def __init__(self, window_size=100):
        self.times = {}
        self.window_size = window_size
        self.windows = {}
    
    def start(self, name):
        if name not in self.times:
            self.times[name] = []
            self.windows[name] = deque(maxlen=self.window_size)
        self.times[name].append(time.time())
    
    def stop(self, name):
        if name in self.times and self.times[name]:
            elapsed = time.time() - self.times[name].pop()
            self.windows[name].append(elapsed)
            return elapsed
        return 0
    
    def get_stats(self, name):
        if name in self.windows and self.windows[name]:
            times = list(self.windows[name])
            return {
                'avg': sum(times) / len(times),
                'min': min(times),
                'max': max(times),
                'last': times[-1]
            }
        return None
    
    def log_stats(self, logger):
        logger.info("=" * 50)
        logger.info("–ü–†–û–§–ò–õ–ò–†–û–í–ê–ù–ò–ï –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò:")
        logger.info("=" * 50)
        for name in self.windows:
            stats = self.get_stats(name)
            if stats:
                logger.info(f"{name:20} | avg: {stats['avg']*1000:6.2f}ms | min: {stats['min']*1000:6.2f}ms | max: {stats['max']*1000:6.2f}ms | last: {stats['last']*1000:6.2f}ms")
        logger.info("=" * 50)

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤—â–∏–∫
profiler = Profiler(window_size=100)

def scale_coordinates(x1, y1, x2, y2, scale_x, scale_y):
    """–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –æ–±—Ä–∞—Ç–Ω–æ –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ä–∞–∑–º–µ—Ä—É"""
    return (
        int(x1 * scale_x),
        int(y1 * scale_y),
        int(x2 * scale_x),
        int(y2 * scale_y)
    )

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –ª–∏—Ü–∞
def get_face_embedding(image: np.ndarray):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –ª–∏—Ü–∞"""
    if image.size == 0:
        return None

    try:
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ RGB
        if image.shape[2] == 3 and image.dtype == np.uint8:
            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        else:
            rgb_image = image

        # –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ª–∏—Ü
        dets = face_detector(rgb_image, 1)
        if len(dets) == 0:
            logger.debug("–õ–∏—Ü–æ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –≤ ROI")
            return None

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫ –ª–∏—Ü–∞
        shape = shape_predictor(rgb_image, dets[0])

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –ª–∏—Ü–∞
        face_descriptor = face_rec_model.compute_face_descriptor(rgb_image, shape, num_jitters=1)
        embedding = np.array(face_descriptor)
        logger.debug("–≠–º–±–µ–¥–¥–∏–Ω–≥ –ª–∏—Ü–∞ —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω")
        return embedding
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –ª–∏—Ü–∞: {str(e)}")
        return None

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ª–∏—Ü–∞
def find_matching_face(embedding):
    """–ò—â–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ª–∏—Ü–∞ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
    try:
        logger.debug("–ù–∞—á–∞–ª–æ –ø–æ–∏—Å–∫–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ª–∏—Ü–∞")
        encoding_str = ",".join(map(str, embedding))
        params = {"embedding_str": encoding_str}
        
        logger.debug(f"–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ —Å–µ—Ä–≤–∏—Å—É —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ª–∏—Ü: {url}")
        response = requests.get(url, params=params, timeout=2)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç
        
        if response.status_code == 200:
            js = response.json()
            logger.debug(f"–û—Ç–≤–µ—Ç —Å–µ—Ä–≤–∏—Å–∞: {js}")
            
            if js.get('status') == 'success':
                person = js.get('person')
                logger.info(f"–ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: {person}")
                return person
            else:
                logger.debug("–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                return None
        else:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ —Å–µ—Ä–≤–∏—Å—É. –°—Ç–∞—Ç—É—Å: {response.status_code}")
            return None
    except requests.exceptions.Timeout:
        logger.error("–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç —Å–µ—Ä–≤–∏—Å–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ª–∏—Ü")
        return None
    except requests.exceptions.RequestException as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ —Å–µ—Ä–≤–∏—Å—É —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ª–∏—Ü: {str(e)}")
        return None
    except Exception as e:
        logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ª–∏—Ü–∞: {str(e)}")
        return None

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –ª–æ–≥–æ–≤ –≤ —Å–µ—Ä–≤–∏—Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
def send_log_to_service(log_message):
    try:
        response = requests.post(LOGGING_SERVICE_URL, json={"message": log_message})
        if response.status_code != 200:
            print(f"Failed to send log: {response.text}")
    except Exception as e:
        print(f"Error sending log: {e}")

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ RTSP –ø–æ—Ç–æ–∫—É
def reconnect_rtsp(max_retries=5, retry_delay=3):
    for attempt in range(max_retries):
        try:
            cap = cv2.VideoCapture(RTSP_INPUT_URL)
            if cap.isOpened():
                cap.set(cv2.CAP_PROP_BUFFERSIZE, 3)
                cap.set(cv2.CAP_PROP_FPS, 30)
                logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ø–æ—Ç–æ–∫—É –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt+1}")
                return cap
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏ –∫ –ø–æ—Ç–æ–∫—É: {str(e)}")
        
        logger.warning(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è {attempt+1}/{max_retries} –Ω–µ —É–¥–∞–ª–∞—Å—å, –ø–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {retry_delay}—Å...")
        time.sleep(retry_delay)
    
    logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ RTSP –ø–æ—Ç–æ–∫—É –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫")
    return None

def interpolate_detections(old_dets, new_dets, alpha):
    """–ò–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä—É–µ—Ç –º–µ–∂–¥—É —Å—Ç–∞—Ä—ã–º–∏ –∏ –Ω–æ–≤—ã–º–∏ –¥–µ—Ç–µ–∫—Ü–∏—è–º–∏"""
    interpolated = []
    
    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
    old_dict = {det['box']: det for det in old_dets}
    new_dict = {det['box']: det for det in new_dets}
    
    # –ò–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–µ—Ç–µ–∫—Ü–∏–∏
    for old_det in old_dets:
        old_box = old_det['box']
        if old_box in new_dict:
            # –ï—Å–ª–∏ –¥–µ—Ç–µ–∫—Ü–∏—è —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ –æ–±–æ–∏—Ö –∫–∞–¥—Ä–∞—Ö, –∏–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä—É–µ–º
            new_box = new_dict[old_box]['box']
            x1 = int(old_box[0] + (new_box[0] - old_box[0]) * alpha)
            y1 = int(old_box[1] + (new_box[1] - old_box[1]) * alpha)
            x2 = int(old_box[2] + (new_box[2] - old_box[2]) * alpha)
            y2 = int(old_box[3] + (new_box[3] - old_box[3]) * alpha)
            
            # –ò–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä—É–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            conf = old_det['conf'] + (new_dict[old_box]['conf'] - old_det['conf']) * alpha
            
            interpolated.append({
                'box': (x1, y1, x2, y2),
                'conf': conf,
                'time': old_det['time'],
                'person': old_det['person']
            })
        elif alpha < 0.7:  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤—Ä–µ–º—è –∂–∏–∑–Ω–∏ –∏—Å—á–µ–∑–∞—é—â–∏—Ö –¥–µ—Ç–µ–∫—Ü–∏–π
            # –ï—Å–ª–∏ –¥–µ—Ç–µ–∫—Ü–∏—è –∏—Å—á–µ–∑–∞–µ—Ç, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –µ—ë –¥–æ–ª—å—à–µ
            interpolated.append(old_det)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –¥–µ—Ç–µ–∫—Ü–∏–∏
    for new_det in new_dets:
        new_box = new_det['box']
        if new_box not in old_dict and alpha > 0.3:  # –†–∞–Ω—å—à–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–æ–≤—ã–µ –¥–µ—Ç–µ–∫—Ü–∏–∏
            interpolated.append(new_det)
    
    return interpolated

def update_detection_cache(boxes, frame_count):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç –∫—ç—à –¥–µ—Ç–µ–∫—Ü–∏–π"""
    global last_detections
    
    # –£–¥–∞–ª—è–µ–º —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –¥–µ—Ç–µ–∫—Ü–∏–∏
    last_detections = [d for d in last_detections if frame_count - d['frame'] < detection_lifetime]
    
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –¥–µ—Ç–µ–∫—Ü–∏–∏
    new_detections = []
    for box in boxes:
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø box –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ
            if hasattr(box, 'xyxy'):
                # –ï—Å–ª–∏ —ç—Ç–æ –æ–±—ä–µ–∫—Ç YOLO
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                conf = box.conf[0].cpu().numpy()
            elif isinstance(box, dict) and 'box' in box:
                # –ï—Å–ª–∏ —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏
                x1, y1, x2, y2 = box['box']
                conf = box['conf']
            else:
                logger.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç box: {type(box)}")
                continue
                
            if conf > 0.5:
                new_detections.append({
                    'box': (int(x1), int(y1), int(x2), int(y2)),
                    'conf': float(conf),
                    'frame': frame_count,
                    'person': None
                })
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ box: {str(e)}")
            continue
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à
    last_detections = new_detections
    if len(last_detections) > MAX_DETECTIONS_CACHE:
        last_detections = last_detections[-MAX_DETECTIONS_CACHE:]

def draw_detections(frame, detections):
    """–û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏ –Ω–∞ –∫–∞–¥—Ä–µ"""
    for det in detections:
        x1, y1, x2, y2 = det['box']
        person = det['person']
        conf = det['conf']
        
        # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Ä–∞–º–∫–∏ —Å –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å—é
        overlay = frame.copy()
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        alpha = 0.3 + 0.4 * conf  # –ü—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å –æ—Ç 0.3 –¥–æ 0.7
        cv2.rectangle(overlay, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)
        
        # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –∏–º–µ–Ω–∏, –µ—Å–ª–∏ –µ—Å—Ç—å
        if person:
            cv2.putText(frame, person, (x1, y1-10), 
                      cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

def process_detection(frame, model):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ"""
    try:
        results = model(frame, verbose=False)
        return results
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–µ—Ç–µ–∫—Ü–∏–∏: {str(e)}")
        return None

def detection_worker():
    """–†–∞–±–æ—á–∏–π –ø–æ—Ç–æ–∫ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏"""
    while True:
        if not frame_queue.empty():
            frame = frame_queue.get()
            if frame is None:
                break
                
            profiler.start('yolo_detection')
            results = process_detection(frame, FACE_MODEL)
            profiler.stop('yolo_detection')
            
            if results is not None:
                detection_queue.put(results)
            else:
                detection_queue.put(None)

def resize_frame(frame, target_width, target_height, buffer=None, interpolation=cv2.INTER_LINEAR):
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ—Å–∞–π–∑ –∫–∞–¥—Ä–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –∫–∞—á–µ—Å—Ç–≤–∞"""
    try:
        if frame is None or frame.size == 0:
            logger.error("–ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –∫–∞–¥—Ä –¥–ª—è —Ä–µ—Å–∞–π–∑–∞")
            return None
            
        if frame.shape[2] != 3:
            logger.error(f"–ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–∞–ª–æ–≤: {frame.shape[2]}")
            return None
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä—ã –≤—Ö–æ–¥–Ω–æ–≥–æ –∫–∞–¥—Ä–∞
        h, w = frame.shape[:2]
        if w < target_width or h < target_height:
            logger.warning(f"–í—Ö–æ–¥–Ω–æ–π –∫–∞–¥—Ä ({w}x{h}) –º–µ–Ω—å—à–µ —Ü–µ–ª–µ–≤–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ ({target_width}x{target_height})")
            interpolation = cv2.INTER_CUBIC  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—é –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è
            
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Å–æ–∑–¥–∞–Ω–Ω—ã–π –±—É—Ñ–µ—Ä –µ—Å–ª–∏ –æ–Ω –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω
        if buffer is not None:
            cv2.resize(frame, (target_width, target_height), dst=buffer, interpolation=interpolation)
            return buffer
        else:
            return cv2.resize(frame, (target_width, target_height), interpolation=interpolation)
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ—Å–∞–π–∑–µ –∫–∞–¥—Ä–∞: {str(e)}")
        return None

def process_frames(parameters):
    global last_face_recognition_time
    frame_count = 0
    start_time = time.time()
    error_count = 0
    max_errors = 10
    
    # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
    scale_x = TARGET_WIDTH / YOLO_WIDTH
    scale_y = TARGET_HEIGHT / YOLO_HEIGHT
    
    logger.info(f"–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è: X={scale_x:.2f}, Y={scale_y:.2f}")
    logger.info(f"–†–∞–∑–º–µ—Ä YOLO: {YOLO_WIDTH}x{YOLO_HEIGHT}")
    logger.info(f"–†–∞–∑–º–µ—Ä –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è: {TARGET_WIDTH}x{TARGET_HEIGHT}")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ –¥–µ—Ç–µ–∫—Ü–∏–∏
    detection_thread = Thread(target=detection_worker)
    detection_thread.start()
    
    while True:
        if not frame_queue.empty():
            frame = frame_queue.get()
            if frame is None:
                break

            try:
                profiler.start('total_frame')
                
                if frame is not None and frame.size > 0:
                    # –†–µ—Å–∞–π–∑ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    profiler.start('resize_display')
                    display_frame = resize_frame(frame, TARGET_WIDTH, TARGET_HEIGHT)
                    profiler.stop('resize_display')
                    
                    if display_frame is None:
                        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ—Å–∞–π–∑–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è")
                        continue
                    
                    if frame_count % process_every_n_frames == 0:
                        # –†–µ—Å–∞–π–∑ –¥–ª—è YOLO
                        profiler.start('resize_yolo')
                        yolo_frame = resize_frame(frame, YOLO_WIDTH, YOLO_HEIGHT)
                        profiler.stop('resize_yolo')
                        
                        if yolo_frame is None:
                            logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ—Å–∞–π–∑–µ –¥–ª—è YOLO")
                            continue
                            
                        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–¥—Ä –≤ –æ—á–µ—Ä–µ–¥—å –¥–µ—Ç–µ–∫—Ü–∏–∏
                        frame_queue.put(yolo_frame.copy())
                        
                        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏
                        results = detection_queue.get()
                        
                        if results is not None:
                            for result in results:
                                boxes = result.boxes
                                scaled_boxes = []
                                profiler.start('process_boxes')
                                for box in boxes:
                                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                                    conf = box.conf[0].cpu().numpy()
                                    if conf > 0.5:
                                        # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∫ —Ä–∞–∑–º–µ—Ä—É –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                                        x1, y1, x2, y2 = scale_coordinates(x1, y1, x2, y2, scale_x, scale_y)
                                        logger.debug(f"–î–µ—Ç–µ–∫—Ü–∏—è: conf={conf:.2f}, box=({x1}, {y1}, {x2}, {y2})")
                                        scaled_boxes.append({
                                            'box': (int(x1), int(y1), int(x2), int(y2)),
                                            'conf': float(conf),
                                            'frame': frame_count,
                                            'person': None
                                        })
                                profiler.stop('process_boxes')
                                
                                with detection_lock:
                                    profiler.start('update_cache')
                                    update_detection_cache(scaled_boxes, frame_count)
                                    profiler.stop('update_cache')
                                
                                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–æ–≤—ã–µ –¥–µ—Ç–µ–∫—Ü–∏–∏
                                profiler.start('face_recognition')
                                for det in scaled_boxes:
                                    x1, y1, x2, y2 = det['box']
                                    if frame_count % face_recognition_interval == 0:
                                        face_roi = frame[y1:y2, x1:x2]
                                        if face_roi.size > 0:
                                            logger.debug(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ ROI —Ä–∞–∑–º–µ—Ä–∞ {face_roi.shape}")
                                            embedding = get_face_embedding(face_roi)
                                            if embedding is not None:
                                                person = find_matching_face(embedding)
                                                with detection_lock:
                                                    for d in last_detections:
                                                        if d['box'] == (x1, y1, x2, y2):
                                                            d['person'] = person
                                profiler.stop('face_recognition')
                    
                    # –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º –¥–µ—Ç–µ–∫—Ü–∏–∏ –Ω–∞ –∫–∞–¥—Ä–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    profiler.start('draw_detections')
                    with detection_lock:
                        draw_detections(display_frame, last_detections)
                    profiler.stop('draw_detections')
                    
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∫–∞–¥—Ä
                    profiler.start('write_frame')
                    out.write(display_frame)
                    profiler.stop('write_frame')
                    
                    # –ò–∑–º–µ—Ä–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
                    total_time = profiler.stop('total_frame')
                    frame_times.append(total_time)
                    frame_count += 1
                    error_count = 0
                    
                    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥
                    if frame_count % 900 == 0:
                        elapsed_time = time.time() - start_time
                        current_fps = frame_count / elapsed_time
                        avg_frame_time = sum(frame_times[-900:]) / len(frame_times[-900:])
                        logger.info("\n" + "=" * 50)
                        logger.info("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò:")
                        logger.info("=" * 50)
                        logger.info(f"FPS: {current_fps:.2f}")
                        logger.info(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–¥—Ä–∞: {avg_frame_time*1000:.2f} –º—Å")
                        logger.info(f"–¶–µ–ª–µ–≤–æ–π FPS: {target_fps}")
                        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–∞–¥—Ä–æ–≤: {frame_count}")
                        logger.info(f"–í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã: {elapsed_time:.1f} —Å–µ–∫")
                        profiler.log_stats(logger)
                else:
                    logger.warning("–ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –∫–∞–¥—Ä")
                    
            except Exception as e:
                error_count += 1
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–∞–¥—Ä–∞: {str(e)}")
                if error_count >= max_errors:
                    logger.error("–ü—Ä–µ–≤—ã—à–µ–Ω–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫, –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ...")
                    return
    
    # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ—Ç–æ–∫ –¥–µ—Ç–µ–∫—Ü–∏–∏
    frame_queue.put(None)
    detection_thread.join()

# –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
parser = argparse.ArgumentParser(description="Process video stream with specific parameters.")
parser.add_argument(
    "--parameters", 
    nargs="+", 
    choices=["person", "car", "cell phone", "traffic light", "helmet"], 
    default=["person"],  # Changed default to an empty list
    help="List of parameters to process: person, car, cell phone, traffic light, helmet."
)
args = parser.parse_args()

# –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏
while True:
    cap = reconnect_rtsp()
    if cap is None:
        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –ø–æ—Ç–æ–∫—É, –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã")
        break

    # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤–∏–¥–µ–æ
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    
    # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—Ö–æ–¥–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞
    logger.info(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—Ö–æ–¥–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞:")
    logger.info(f"–†–∞–∑–º–µ—Ä: {frame_width}x{frame_height}")
    logger.info(f"FPS: {fps}")
    logger.info(f"–§–æ—Ä–º–∞—Ç: {cap.get(cv2.CAP_PROP_FOURCC)}")
    logger.info(f"–ë—É—Ñ–µ—Ä: {cap.get(cv2.CAP_PROP_BUFFERSIZE)}")

    if fps <= 0:
        logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å FPS, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 30")
        fps = 30

    logger.info(f"üé• –í—Ö–æ–¥–Ω–æ–π –ø–æ—Ç–æ–∫: {frame_width}x{frame_height} –ø—Ä–∏ {fps} FPS")
    logger.info(f"üîÑ –ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ {RTSP_OUTPUT_URL}")

    # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ GStreamer –¥–ª—è –≤—ã–≤–æ–¥–∞ RTSP
    gst_pipeline = (
        f'appsrc ! videoconvert ! video/x-raw,format=I420 ! '
        f'x264enc speed-preset=ultrafast tune=zerolatency bitrate=4096 key-int-max=30 ! '  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –±–∏—Ç—Ä–µ–π—Ç
        f'video/x-h264,profile=baseline ! rtspclientsink location={RTSP_OUTPUT_URL} protocols=tcp'
    )
    logger.info(f"GStreamer pipeline: {gst_pipeline}")
    
    out = cv2.VideoWriter(
        gst_pipeline,
        cv2.CAP_GSTREAMER, 0, fps, (TARGET_WIDTH, TARGET_HEIGHT), True
    )

    if not out.isOpened():
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤—ã—Ö–æ–¥–Ω–æ–π RTSP –ø–æ—Ç–æ–∫!")
        cap.release()
        continue

    # –ó–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–¥—Ä–æ–≤
    processor_thread = Thread(target=process_frames, args=(args.parameters,))
    processor_thread.start()

    frame_ind = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –∫–∞–¥—Ä–∞ –∏–∑ RTSP –ø–æ—Ç–æ–∫–∞!")
            break

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–¥—Ä –≤ –æ—á–µ—Ä–µ–¥—å, –¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω –ø–æ–≤—Ä–µ–∂–¥–µ–Ω
        if not frame_queue.full():
            frame_queue.put(frame)
        frame_ind += 1

    # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ—Ç–æ–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    frame_queue.put(None)
    processor_thread.join()

    # –û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤
    out.release()
    cap.release()
    
    logger.info("–ü–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ø–æ—Ç–æ–∫—É...")
    time.sleep(3)