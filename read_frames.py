import cv2
import numpy as np
import dlib
import requests
from ultralytics import YOLO
from threading import Thread
from queue import Queue


from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ RTSP
RTSP_INPUT_URL = "rtsp://mediamtx:8554/stream"
RTSP_OUTPUT_URL = "rtsp://mediamtx:8554/5"

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ YOLO
model = YOLO("ml_models/yolov8n-face.pt")
face_detector = dlib.get_frontal_face_detector()
shape_predictor = dlib.shape_predictor("ml_models/shape_predictor_68_face_landmarks.dat")
face_rec_model = dlib.face_recognition_model_v1("ml_models/dlib_face_recognition_resnet_model_v1.dat")

used_faces = []

url = "http://face_recognition:8000/find_face"

def get_face_embedding(image: np.ndarray):
    # –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ñ–∏—á–∏ –ª–∏—Ü–∞ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    dets = face_detector(image, 1)
    if len(dets) == 0:
        return None
    shape = shape_predictor(image, dets[0])
    face_descriptor = face_rec_model.compute_face_descriptor(image, shape)
    return np.array(face_descriptor)

def find_matching_face(embedding):
    encoding_str = ",".join(map(str, embedding))
    params = {"embedding_str": encoding_str}

    response = requests.get(url, params=params)
    if response.status_code == 200:
        js = response.json()
        if js['status'] == 'success':
            return js['person']
        else:
            return None


frame_queue = Queue(maxsize=10)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –æ—á–µ—Ä–µ–¥–∏

def get_face_embedding(image: np.ndarray):
    # –ò–∑–≤–ª–µ–∫–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –ª–∏—Ü–∞ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    if image.size == 0:
        return None

    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ RGB, –µ—Å–ª–∏ –æ–Ω–æ –≤ BGR (–∫–∞–∫ –≤ OpenCV)
    if image.shape[2] == 3 and image.dtype == np.uint8:
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    else:
        rgb_image = image

    # –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ª–∏—Ü
    dets = face_detector(rgb_image, 1)
    if len(dets) == 0:
        return None

    # –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫ –ª–∏—Ü–∞
    shape = shape_predictor(rgb_image, dets[0])

    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –ª–∏—Ü–∞
    face_descriptor = face_rec_model.compute_face_descriptor(rgb_image, shape, num_jitters=1)
    return np.array(face_descriptor)



def process_frames():
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–∞–¥—Ä—ã –∏–∑ –æ—á–µ—Ä–µ–¥–∏
    while True:
        if not frame_queue.empty():
            frame = frame_queue.get()
            if frame is None:
                break

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞ —Å –ø–æ–º–æ—â—å—é YOLO
            results = model(frame)
            annotated_frame = results[0].plot(conf=False)


            # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –ª–∏—Ü —Å –ø–æ–º–æ—â—å—é dlib
            for result in results:
                for box in result.boxes:
                    if int(box.cls) == 0:  # –ö–ª–∞—Å—Å 0 —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏—Ü—É –≤ YOLO
                        x1, y1, x2, y2 = map(int, box.xyxy[0])
                        face_image = frame[y1:y2, x1:x2]

                        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –ª–∏—Ü–∞
                        embedding = get_face_embedding(face_image)
                        if embedding is not None:
                            # –ü–æ–∏—Å–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
                            match = None

                            for name, encoding in used_faces:
                                dist = np.linalg.norm(encoding - embedding)
                                min_dist = float("inf")
                                if dist < 0.6 and dist < min_dist:
                                    match = name
                                    min_dist = dist
                            if match is None:
                                match = find_matching_face(embedding)
                                if match:
                                    used_faces.append((match, embedding))
                            if match:
                                # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∏–º–µ–Ω–µ–º –Ω–∞ –∫–∞–¥—Ä
                                cv2.putText(annotated_frame, match, (x1 + 100, y1 - 10),
                                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

            # –û—Ç–ø—Ä–∞–≤–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –∫–∞–¥—Ä–∞ –≤ –≤—ã—Ö–æ–¥–Ω–æ–π RTSP-–ø–æ—Ç–æ–∫
            out.write(annotated_frame)

# –û—Ç–∫—Ä—ã—Ç–∏–µ RTSP-–ø–æ—Ç–æ–∫–∞
cap = cv2.VideoCapture(RTSP_INPUT_URL)
if not cap.isOpened():
    print("‚ùå Error: Cannot open RTSP input stream!")
    exit()

# –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤–∏–¥–µ–æ
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = cap.get(cv2.CAP_PROP_FPS)

if fps <= 0:
    print("‚ö†Ô∏è Warning: FPS retrieval failed, setting default FPS to 30")
    fps = 30

print(f"üé• Input stream opened: {frame_width}x{frame_height} at {fps} FPS")
print(f"üîÑ Forwarding to {RTSP_OUTPUT_URL}")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ GStreamer –¥–ª—è –≤—ã–≤–æ–¥–∞ RTSP
out = cv2.VideoWriter(
    f'appsrc ! videoconvert ! video/x-raw,format=I420 ! '
    f'x264enc speed-preset=ultrafast bitrate=1024 key-int-max={int(fps*2)} ! '
    f'video/x-h264,profile=baseline ! rtspclientsink protocols=tcp location={RTSP_OUTPUT_URL}',
    cv2.CAP_GSTREAMER, 0, fps, (frame_width, frame_height), True
)

if not out.isOpened():
    print("‚ùå Error: Cannot open RTSP output stream!")
    cap.release()
    exit()

# –ó–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–¥—Ä–æ–≤
processor_thread = Thread(target=process_frames)
processor_thread.start()

frame_ind = 0
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("‚ùå Error: Failed to read frame from RTSP stream!")
        break

    frame_queue.put(frame)

    frame_ind += 1

# –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ—Ç–æ–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
frame_queue.put(None)
processor_thread.join()

# –û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤
out.release()
cap.release()